Setting up Discriminator
WARNING:tensorflow:From /home/girish/miniconda3/envs/finalproject/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Setting up Generator
WARNING:tensorflow:From /home/girish/miniconda3/envs/finalproject/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Training iter: 0
2020-05-05 00:34:50.015690: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-05-05 00:34:50.037696: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600000000 Hz
2020-05-05 00:34:50.038646: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x562648718400 executing computations on platform Host. Devices:
2020-05-05 00:34:50.038714: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
WARNING:tensorflow:From /home/girish/miniconda3/envs/finalproject/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?
Gan loss: [1180383.8, 84.2982, 11802.995]; Disc loss: 68.54249572753906
40/40 [==============================] - 2s 50ms/sample - loss: 142.5368
40/40 [==============================] - 2s 44ms/sample - loss: 31.3860
40/40 [==============================] - 9s 216ms/sample - loss: 322102.4109 - model_loss: 59.2496 - model_1_loss: 2359.6609
[322102.4109375, 59.249588, 2359.661]
Training iter: 1
Gan loss: [1153723.8, 62.09393, 11536.616]; Disc loss: 36.48442459106445
Training iter: 2
Gan loss: [1166809.4, 40.352898, 11667.69]; Disc loss: 41.23155212402344
Training iter: 3
Gan loss: [1153454.4, 18.58762, 11534.357]; Disc loss: 29.684877395629883
Training iter: 4
Gan loss: [1137181.9, 12.923835, 11371.689]; Disc loss: 14.92159652709961
Training iter: 5
Gan loss: [1168647.1, 7.757535, 11686.394]; Disc loss: 4.806246280670166
40/40 [==============================] - 2s 43ms/sample - loss: 23.2667
40/40 [==============================] - 2s 43ms/sample - loss: 2.8712
40/40 [==============================] - 8s 209ms/sample - loss: 308658.4156 - model_loss: 6.7083 - model_1_loss: 2278.9514
[308658.415625, 6.708267, 2278.9514]
Training iter: 6
Gan loss: [1160026.9, 5.258478, 11600.216]; Disc loss: 2.7177014350891113
Training iter: 7
Gan loss: [1180838.8, 4.321875, 11808.344]; Disc loss: 1.9150134325027466
Training iter: 8
Gan loss: [1156398.1, 3.452419, 11563.946]; Disc loss: 1.5128734111785889
Training iter: 9
Gan loss: [1197385.4, 2.4681175, 11973.829]; Disc loss: 0.9726377129554749
Training iter: 10
Gan loss: [1158727.1, 2.3469496, 11587.248]; Disc loss: 0.9869372248649597
40/40 [==============================] - 2s 43ms/sample - loss: 22.0614
40/40 [==============================] - 2s 43ms/sample - loss: 2.4079
40/40 [==============================] - 8s 209ms/sample - loss: 331244.0156 - model_loss: 6.6803 - model_1_loss: 2414.8491
[331244.015625, 6.680348, 2414.849]
Training iter: 11
Gan loss: [1194281.9, 2.0046792, 11942.799]; Disc loss: 0.7537431716918945
Training iter: 12
Gan loss: [1177300.0, 1.5749844, 11772.983]; Disc loss: 0.649578869342804
Training iter: 13
Gan loss: [1217866.1, 1.5031636, 12178.646]; Disc loss: 0.4990565776824951
Training iter: 14
Gan loss: [1137536.0, 1.632251, 11375.344]; Disc loss: 0.6069859266281128
Training iter: 15
Gan loss: [1202209.8, 1.1218275, 12022.086]; Disc loss: 0.39867889881134033
40/40 [==============================] - 2s 43ms/sample - loss: 26.3844
40/40 [==============================] - 2s 43ms/sample - loss: 2.1355
40/40 [==============================] - 8s 210ms/sample - loss: 319941.5469 - model_loss: 6.1658 - model_1_loss: 2373.0242
[319941.546875, 6.1658087, 2373.0242]
Training iter: 16
Gan loss: [1163464.8, 1.1635681, 11634.637]; Disc loss: 0.37712520360946655
Training iter: 17
Gan loss: [1157981.4, 1.0776851, 11579.803]; Disc loss: 0.38052594661712646
Training iter: 18
Gan loss: [1174741.6, 0.86666065, 11747.407]; Disc loss: 0.2961348295211792
Training iter: 19
Gan loss: [1183086.2, 0.78775036, 11830.855]; Disc loss: 0.28738170862197876
Training iter: 20
Gan loss: [1171329.9, 0.8028865, 11713.291]; Disc loss: 0.2787708342075348
40/40 [==============================] - 2s 44ms/sample - loss: 27.7272
40/40 [==============================] - 2s 43ms/sample - loss: 1.4659
40/40 [==============================] - 8s 210ms/sample - loss: 333731.0031 - model_loss: 4.7351 - model_1_loss: 2412.5811
[333731.003125, 4.7351007, 2412.581]
Training iter: 21
Gan loss: [1178152.0, 0.63014984, 11781.514]; Disc loss: 0.2183070182800293
Training iter: 22
Gan loss: [1190020.2, 0.6711054, 11900.196]; Disc loss: 0.2390332818031311
Training iter: 23
Gan loss: [1204708.9, 0.5329418, 12047.084]; Disc loss: 0.16250114142894745
Training iter: 24
Gan loss: [1177616.1, 0.59462106, 11776.155]; Disc loss: 0.17623642086982727
Training iter: 25
Gan loss: [1121034.4, 0.64435196, 11210.338]; Disc loss: 0.23579122126102448
40/40 [==============================] - 2s 43ms/sample - loss: 28.0437
40/40 [==============================] - 2s 43ms/sample - loss: 1.7090
40/40 [==============================] - 8s 210ms/sample - loss: 301102.5578 - model_loss: 6.1455 - model_1_loss: 2199.3245
[301102.5578125, 6.1455154, 2199.3245]
Training iter: 26
Gan loss: [1158688.8, 0.5685868, 11586.881]; Disc loss: 0.1748517006635666
Training iter: 27
Gan loss: [1148895.0, 0.5213022, 11488.945]; Disc loss: 0.1671983003616333
Training iter: 28
Gan loss: [1164633.2, 0.51901513, 11646.328]; Disc loss: 0.17204450070858002
Training iter: 29
Gan loss: [1126531.8, 0.4492941, 11265.3125]; Disc loss: 0.14242489635944366
Training iter: 30
Gan loss: [1169244.0, 0.39511448, 11692.437]; Disc loss: 0.12914270162582397
40/40 [==============================] - 2s 44ms/sample - loss: 31.5754
40/40 [==============================] - 2s 43ms/sample - loss: 1.3425
40/40 [==============================] - 8s 210ms/sample - loss: 315241.7906 - model_loss: 6.0775 - model_1_loss: 2294.2993
[315241.790625, 6.0774627, 2294.2993]
Training iter: 31
Gan loss: [1176954.0, 0.33411938, 11769.536]; Disc loss: 0.11459791660308838
Training iter: 32
Gan loss: [1111030.8, 0.43064177, 11110.304]; Disc loss: 0.13844077289104462
Training iter: 33
Gan loss: [1147955.2, 0.4674762, 11479.547]; Disc loss: 0.11909547448158264
Training iter: 34
Gan loss: [1140351.5, 0.3515444, 11403.512]; Disc loss: 0.107258141040802
Training iter: 35
Gan loss: [1184274.6, 0.3047142, 11842.744]; Disc loss: 0.0970672070980072
40/40 [==============================] - 2s 43ms/sample - loss: 33.3879
40/40 [==============================] - 2s 43ms/sample - loss: 1.1744
40/40 [==============================] - 8s 209ms/sample - loss: 309754.8328 - model_loss: 6.1503 - model_1_loss: 2292.7466
[309754.8328125, 6.1502724, 2292.7466]
Training iter: 36
Gan loss: [1137523.9, 0.32599777, 11375.234]; Disc loss: 0.10425502061843872
Training iter: 37
Gan loss: [1169411.6, 0.28429592, 11694.114]; Disc loss: 0.10256222635507584
Training iter: 38
Gan loss: [1203279.5, 0.28811514, 12032.793]; Disc loss: 0.09028832614421844
Training iter: 39
Gan loss: [1168325.5, 0.3012938, 11683.252]; Disc loss: 0.10158586502075195
Training iter: 40
Gan loss: [1182907.8, 0.24245815, 11829.075]; Disc loss: 0.07527289539575577
40/40 [==============================] - 2s 44ms/sample - loss: 36.6144
40/40 [==============================] - 2s 43ms/sample - loss: 0.9381
40/40 [==============================] - 8s 209ms/sample - loss: 328238.9922 - model_loss: 5.9080 - model_1_loss: 2405.3848
[328238.9921875, 5.9079695, 2405.3848]
Training iter: 41
Gan loss: [1151182.6, 0.21042049, 11511.823]; Disc loss: 0.06754947453737259
Training iter: 42
Gan loss: [1175636.9, 0.21304657, 11756.366]; Disc loss: 0.06385928392410278
Training iter: 43
Gan loss: [1169599.9, 0.2193605, 11695.996]; Disc loss: 0.06734775006771088
Training iter: 44
Gan loss: [1187540.6, 0.21636711, 11875.404]; Disc loss: 0.06278520822525024
Training iter: 45
Gan loss: [1159457.1, 0.28760356, 11594.568]; Disc loss: 0.08695795387029648
40/40 [==============================] - 2s 43ms/sample - loss: 37.3879
40/40 [==============================] - 2s 43ms/sample - loss: 1.0199
40/40 [==============================] - 8s 210ms/sample - loss: 312231.9297 - model_loss: 7.3742 - model_1_loss: 2309.3137
[312231.9296875, 7.374155, 2309.3137]
Training iter: 46
Gan loss: [1147005.1, 0.2636457, 11470.049]; Disc loss: 0.076176717877388
Training iter: 47
Gan loss: [1169582.5, 0.2023077, 11695.822]; Disc loss: 0.06250660866498947
Training iter: 48
Gan loss: [1161128.5, 0.20978083, 11611.282]; Disc loss: 0.06662002950906754
Training iter: 49
Gan loss: [1180558.8, 0.1844849, 11805.586]; Disc loss: 0.05470288544893265
Training iter: 50
Gan loss: [1217385.2, 0.1687184, 12173.852]; Disc loss: 0.050578318536281586
40/40 [==============================] - 2s 43ms/sample - loss: 39.6749
40/40 [==============================] - 2s 43ms/sample - loss: 0.8968
40/40 [==============================] - 8s 210ms/sample - loss: 324238.1281 - model_loss: 6.9869 - model_1_loss: 2389.8250
[324238.128125, 6.9868956, 2389.825]
Training iter: 51
Gan loss: [1174355.4, 0.17801023, 11743.553]; Disc loss: 0.05461136996746063
Training iter: 52
Gan loss: [1223149.5, 0.14393032, 12231.494]; Disc loss: 0.04400144889950752
Training iter: 53
Gan loss: [1225102.6, 0.15071726, 12251.025]; Disc loss: 0.0449271984398365
Training iter: 54
Gan loss: [1188770.9, 0.16737485, 11887.708]; Disc loss: 0.06338401883840561
Training iter: 55
Gan loss: [1154541.8, 0.17729035, 11545.416]; Disc loss: 0.05778709053993225
40/40 [==============================] - 2s 43ms/sample - loss: 39.4120
40/40 [==============================] - 2s 43ms/sample - loss: 0.8152
40/40 [==============================] - 8s 210ms/sample - loss: 343916.5016 - model_loss: 8.1482 - model_1_loss: 2538.8650
[343916.5015625, 8.148166, 2538.865]
Training iter: 56
Gan loss: [1195249.5, 0.16870016, 11952.494]; Disc loss: 0.04870026558637619
Training iter: 57
Gan loss: [1175936.2, 0.16235173, 11759.361]; Disc loss: 0.047464706003665924
Training iter: 58
Gan loss: [1155167.1, 0.16478503, 11551.67]; Disc loss: 0.0549500435590744
Training iter: 59
Gan loss: [1153377.0, 0.15412366, 11533.769]; Disc loss: 0.045754462480545044
Training iter: 60
Gan loss: [1212801.2, 0.13322552, 12128.012]; Disc loss: 0.04062576964497566
40/40 [==============================] - 2s 43ms/sample - loss: 41.9248
40/40 [==============================] - 2s 43ms/sample - loss: 0.7828
40/40 [==============================] - 8s 209ms/sample - loss: 326710.3062 - model_loss: 8.4355 - model_1_loss: 2403.8567
[326710.30625, 8.43549, 2403.8567]
Training iter: 61
Gan loss: [1161648.1, 0.15041032, 11616.48]; Disc loss: 0.04414120689034462
Training iter: 62
Gan loss: [1169465.2, 0.1622558, 11694.651]; Disc loss: 0.046324700117111206
Training iter: 63
Gan loss: [1117206.1, 0.16120662, 11172.061]; Disc loss: 0.04322972893714905
Training iter: 64
Gan loss: [1178135.6, 0.14387518, 11781.3545]; Disc loss: 0.04185890406370163
Training iter: 65
Gan loss: [1198189.1, 0.1366757, 11981.89]; Disc loss: 0.04181109368801117
40/40 [==============================] - 2s 43ms/sample - loss: 43.5290
40/40 [==============================] - 2s 43ms/sample - loss: 0.7494
40/40 [==============================] - 8s 210ms/sample - loss: 307953.3062 - model_loss: 7.3887 - model_1_loss: 2292.9712
[307953.30625, 7.3886557, 2292.9712]
Training iter: 66
Gan loss: [1146314.5, 0.14886111, 11463.144]; Disc loss: 0.04375047609210014
Training iter: 67
Gan loss: [1188754.1, 0.10739908, 11887.54]; Disc loss: 0.03241901844739914
Training iter: 68
Gan loss: [1175685.5, 0.13072845, 11756.854]; Disc loss: 0.03835533559322357
Training iter: 69
Gan loss: [1147105.2, 0.13829166, 11471.051]; Disc loss: 0.04033539444208145
Training iter: 70
Gan loss: [1157961.2, 0.14194137, 11579.611]; Disc loss: 0.04807282239198685
40/40 [==============================] - 2s 44ms/sample - loss: 45.9221
40/40 [==============================] - 2s 43ms/sample - loss: 0.6436
40/40 [==============================] - 8s 210ms/sample - loss: 325000.8156 - model_loss: 8.3671 - model_1_loss: 2397.9785
[325000.815625, 8.367058, 2397.9785]
Training iter: 71
Gan loss: [1151516.8, 0.105683446, 11515.166]; Disc loss: 0.03344864025712013
Training iter: 72
Gan loss: [1133882.0, 0.12002996, 11338.818]; Disc loss: 0.03339614346623421
Training iter: 73
Gan loss: [1145787.4, 0.121217445, 11457.873]; Disc loss: 0.03327091038227081
Training iter: 74
Gan loss: [1171162.4, 0.09267841, 11711.623]; Disc loss: 0.03062060847878456
Training iter: 75
Gan loss: [1119715.2, 0.1319023, 11197.151]; Disc loss: 0.03899890184402466
40/40 [==============================] - 2s 43ms/sample - loss: 45.7379
40/40 [==============================] - 2s 43ms/sample - loss: 0.4967
40/40 [==============================] - 8s 210ms/sample - loss: 308471.8078 - model_loss: 7.4520 - model_1_loss: 2263.3823
[308471.8078125, 7.4519567, 2263.3823]
Training iter: 76
Gan loss: [1173928.5, 0.1022937, 11739.283]; Disc loss: 0.03238382935523987
Training iter: 77
Gan loss: [1170771.6, 0.11697108, 11707.715]; Disc loss: 0.03371152654290199
Training iter: 78
Gan loss: [1204972.9, 0.08983105, 12049.728]; Disc loss: 0.028585346415638924
Training iter: 79
Gan loss: [1173357.0, 0.09375495, 11733.569]; Disc loss: 0.029118716716766357
Training iter: 80
Gan loss: [1128703.2, 0.11202968, 11287.031]; Disc loss: 0.03404678776860237
40/40 [==============================] - 2s 44ms/sample - loss: 48.9190
40/40 [==============================] - 2s 43ms/sample - loss: 0.5808
40/40 [==============================] - 8s 210ms/sample - loss: 284221.7453 - model_loss: 7.8004 - model_1_loss: 2214.5061
[284221.7453125, 7.800428, 2214.506]
Training iter: 81
Gan loss: [1162546.4, 0.087960534, 11625.463]; Disc loss: 0.025301706045866013
Training iter: 82
Gan loss: [1149993.6, 0.099850565, 11499.936]; Disc loss: 0.03126928582787514
Training iter: 83
Gan loss: [1197753.1, 0.081849575, 11977.53]; Disc loss: 0.024745535105466843
Training iter: 84
Gan loss: [1180103.5, 0.09199906, 11801.033]; Disc loss: 0.027873191982507706
Training iter: 85
Gan loss: [1134027.5, 0.114130124, 11340.273]; Disc loss: 0.030555162578821182
40/40 [==============================] - 2s 44ms/sample - loss: 49.1069
40/40 [==============================] - 2s 43ms/sample - loss: 0.5086
40/40 [==============================] - 8s 211ms/sample - loss: 304195.7406 - model_loss: 7.8629 - model_1_loss: 2322.7568
[304195.740625, 7.8628573, 2322.7568]
Training iter: 86
Gan loss: [1196945.6, 0.07682003, 11969.455]; Disc loss: 0.023170769214630127
Training iter: 87
Gan loss: [1122615.1, 0.090259984, 11226.149]; Disc loss: 0.027116810902953148
Training iter: 88
Gan loss: [1186037.1, 0.080548406, 11860.37]; Disc loss: 0.025655418634414673
Training iter: 89
Gan loss: [1217296.0, 0.072307855, 12172.959]; Disc loss: 0.02352765202522278
Training iter: 90
Gan loss: [1151875.4, 0.09608035, 11518.752]; Disc loss: 0.03124246373772621
40/40 [==============================] - 2s 43ms/sample - loss: 50.2332
40/40 [==============================] - 2s 43ms/sample - loss: 0.4500
40/40 [==============================] - 8s 209ms/sample - loss: 315019.8062 - model_loss: 6.5586 - model_1_loss: 2339.3735
[315019.80625, 6.5585747, 2339.3735]
Training iter: 91
Gan loss: [1155540.6, 0.08472973, 11555.405]; Disc loss: 0.028210286051034927
Training iter: 92
Gan loss: [1150308.5, 0.08536116, 11503.084]; Disc loss: 0.026505427435040474
Training iter: 93
Gan loss: [1158230.2, 0.08457927, 11582.301]; Disc loss: 0.026792969554662704
Training iter: 94
Gan loss: [1153296.9, 0.07090616, 11532.968]; Disc loss: 0.02063700556755066
Training iter: 95
Gan loss: [1169317.8, 0.0812626, 11693.177]; Disc loss: 0.02444527857005596
40/40 [==============================] - 2s 43ms/sample - loss: 51.1290
40/40 [==============================] - 2s 43ms/sample - loss: 0.3795
40/40 [==============================] - 8s 212ms/sample - loss: 328541.1844 - model_loss: 7.3386 - model_1_loss: 2419.7725
[328541.184375, 7.338601, 2419.7725]
Training iter: 96
Gan loss: [1177768.1, 0.0744997, 11777.68]; Disc loss: 0.025387074798345566
Training iter: 97
Gan loss: [1226584.8, 0.0596832, 12265.848]; Disc loss: 0.017475711181759834
Training iter: 98
Gan loss: [1174569.9, 0.075325206, 11745.697]; Disc loss: 0.02260928601026535
Training iter: 99
Gan loss: [1177022.0, 0.07624802, 11770.219]; Disc loss: 0.02201492339372635
Training iter: 100
Gan loss: [1141595.9, 0.07314218, 11415.958]; Disc loss: 0.022727493196725845
40/40 [==============================] - 2s 43ms/sample - loss: 53.5169
40/40 [==============================] - 2s 43ms/sample - loss: 0.4220
40/40 [==============================] - 8s 210ms/sample - loss: 329141.5359 - model_loss: 7.1043 - model_1_loss: 2400.6069
[329141.5359375, 7.1043425, 2400.607]
Training iter: 101
Gan loss: [1171446.8, 0.07609175, 11714.466]; Disc loss: 0.02210816740989685
Training iter: 102
Gan loss: [1130318.2, 0.09025216, 11303.182]; Disc loss: 0.026618437841534615
Training iter: 103
Gan loss: [1158613.9, 0.061675422, 11586.139]; Disc loss: 0.019686568528413773
Training iter: 104
Gan loss: [1163269.4, 0.0577025, 11632.693]; Disc loss: 0.017391562461853027
Training iter: 105
Gan loss: [1148233.4, 0.07115796, 11482.333]; Disc loss: 0.021357692778110504
40/40 [==============================] - 2s 43ms/sample - loss: 52.0684
40/40 [==============================] - 2s 43ms/sample - loss: 0.3810
40/40 [==============================] - 8s 211ms/sample - loss: 319119.3453 - model_loss: 6.8020 - model_1_loss: 2353.3303
[319119.3453125, 6.8019857, 2353.3303]
Training iter: 106
Gan loss: [1153097.0, 0.06578513, 11530.969]; Disc loss: 0.019978608936071396
Training iter: 107
Gan loss: [1171970.2, 0.067328915, 11719.701]; Disc loss: 0.01758040115237236
Training iter: 108
Gan loss: [1173808.9, 0.067539155, 11738.088]; Disc loss: 0.018872033804655075
Training iter: 109
Gan loss: [1133833.1, 0.06800295, 11338.33]; Disc loss: 0.01986987143754959
Training iter: 110
Gan loss: [1201814.8, 0.062885985, 12018.146]; Disc loss: 0.01819201372563839
40/40 [==============================] - 2s 43ms/sample - loss: 55.1197
40/40 [==============================] - 2s 43ms/sample - loss: 0.3829
40/40 [==============================] - 8s 210ms/sample - loss: 314276.5938 - model_loss: 7.7730 - model_1_loss: 2252.1179
[314276.59375, 7.772955, 2252.118]
Training iter: 111
Gan loss: [1197477.0, 0.057431556, 11974.7705]; Disc loss: 0.017586495727300644
Training iter: 112
Gan loss: [1136300.0, 0.07091823, 11362.999]; Disc loss: 0.021219462156295776
Training iter: 113
Gan loss: [1111079.9, 0.062145934, 11110.799]; Disc loss: 0.019470006227493286
Training iter: 114
Gan loss: [1164015.0, 0.064089745, 11640.148]; Disc loss: 0.017310980707406998
Training iter: 115
Gan loss: [1182334.6, 0.062281203, 11823.346]; Disc loss: 0.01662299782037735
40/40 [==============================] - 2s 43ms/sample - loss: 55.8955
40/40 [==============================] - 2s 43ms/sample - loss: 0.4104
40/40 [==============================] - 8s 210ms/sample - loss: 305923.4828 - model_loss: 8.0086 - model_1_loss: 2220.1934
[305923.4828125, 8.008608, 2220.1934]
Training iter: 116
Gan loss: [1139431.6, 0.06209649, 11394.316]; Disc loss: 0.020099861547350883
Training iter: 117
Gan loss: [1154174.9, 0.074279964, 11541.747]; Disc loss: 0.019981898367404938
Training iter: 118
Gan loss: [1165618.8, 0.061039995, 11656.1875]; Disc loss: 0.014981593005359173
Training iter: 119
Gan loss: [1154192.5, 0.052435603, 11541.925]; Disc loss: 0.017231404781341553
Training iter: 120
Gan loss: [1167756.9, 0.052510522, 11677.569]; Disc loss: 0.016035661101341248
40/40 [==============================] - 2s 44ms/sample - loss: 54.8210
40/40 [==============================] - 2s 44ms/sample - loss: 0.3567
40/40 [==============================] - 8s 210ms/sample - loss: 310313.0250 - model_loss: 7.5927 - model_1_loss: 2285.4431
[310313.025, 7.592655, 2285.443]
Training iter: 121
Gan loss: [1138939.1, 0.052330114, 11389.392]; Disc loss: 0.014855596236884594
Training iter: 122
Gan loss: [1142911.1, 0.05906031, 11429.111]; Disc loss: 0.01549609936773777
Training iter: 123
Gan loss: [1165735.5, 0.051270112, 11657.3545]; Disc loss: 0.014168672263622284
Training iter: 124
Gan loss: [1160424.6, 0.052285396, 11604.246]; Disc loss: 0.01441260613501072
Training iter: 125
Gan loss: [1180909.8, 0.049472358, 11809.098]; Disc loss: 0.013542523607611656
40/40 [==============================] - 2s 44ms/sample - loss: 55.8321
40/40 [==============================] - 2s 43ms/sample - loss: 0.4192
40/40 [==============================] - 8s 210ms/sample - loss: 327062.8656 - model_loss: 7.4703 - model_1_loss: 2358.0701
[327062.865625, 7.4702597, 2358.07]
Training iter: 126
Gan loss: [1160003.5, 0.0568318, 11600.035]; Disc loss: 0.015305986627936363
Training iter: 127
Gan loss: [1191415.4, 0.047078636, 11914.154]; Disc loss: 0.013454434461891651
Training iter: 128
Gan loss: [1163903.6, 0.04955745, 11639.036]; Disc loss: 0.014704309403896332
Training iter: 129
Gan loss: [1189171.1, 0.053339522, 11891.711]; Disc loss: 0.01436581276357174
Training iter: 130
Gan loss: [1182151.9, 0.044649564, 11821.519]; Disc loss: 0.014317446388304234
40/40 [==============================] - 2s 43ms/sample - loss: 55.2442
40/40 [==============================] - 2s 43ms/sample - loss: 0.3368
40/40 [==============================] - 8s 210ms/sample - loss: 330899.0891 - model_loss: 8.5707 - model_1_loss: 2433.0068
[330899.0890625, 8.570712, 2433.0068]
Training iter: 131
Gan loss: [1211791.2, 0.045541283, 12117.912]; Disc loss: 0.011680925264954567
Training iter: 132
Gan loss: [1136872.6, 0.060939398, 11368.727]; Disc loss: 0.01805773749947548
Training iter: 133
Gan loss: [1206844.9, 0.04546362, 12068.449]; Disc loss: 0.012609170749783516
Training iter: 134
Gan loss: [1157674.0, 0.04955856, 11576.74]; Disc loss: 0.013067861087620258
Training iter: 135
Gan loss: [1168502.4, 0.051019497, 11685.023]; Disc loss: 0.014858130365610123
40/40 [==============================] - 2s 43ms/sample - loss: 56.2033
40/40 [==============================] - 2s 43ms/sample - loss: 0.3410
40/40 [==============================] - 8s 210ms/sample - loss: 315814.2531 - model_loss: 7.5475 - model_1_loss: 2291.4321
[315814.253125, 7.5474777, 2291.4321]
Training iter: 136
Gan loss: [1170676.0, 0.045489114, 11706.76]; Disc loss: 0.012988206930458546
Training iter: 137
Gan loss: [1175403.2, 0.04546084, 11754.032]; Disc loss: 0.013392554596066475
Training iter: 138
Gan loss: [1177519.1, 0.04739756, 11775.191]; Disc loss: 0.013875212520360947
Training iter: 139
Gan loss: [1179777.9, 0.04031385, 11797.779]; Disc loss: 0.011945610865950584
Training iter: 140
Gan loss: [1182287.5, 0.04505179, 11822.875]; Disc loss: 0.0136262197047472
40/40 [==============================] - 2s 44ms/sample - loss: 55.0945
40/40 [==============================] - 2s 43ms/sample - loss: 0.3352
40/40 [==============================] - 8s 211ms/sample - loss: 330373.1875 - model_loss: 6.5067 - model_1_loss: 2397.0596
[330373.1875, 6.5066686, 2397.0596]
Training iter: 141
Gan loss: [1209547.6, 0.038417067, 12095.477]; Disc loss: 0.009996134787797928
Training iter: 142
Gan loss: [1177439.9, 0.041763708, 11774.398]; Disc loss: 0.011374023742973804
Training iter: 143
Gan loss: [1120820.8, 0.055813577, 11208.208]; Disc loss: 0.016488442197442055
Training iter: 144
Gan loss: [1157883.9, 0.04948671, 11578.839]; Disc loss: 0.013275660574436188
Training iter: 145
Gan loss: [1150043.1, 0.045368638, 11500.432]; Disc loss: 0.012349948287010193
40/40 [==============================] - 2s 43ms/sample - loss: 56.7807
40/40 [==============================] - 2s 43ms/sample - loss: 0.3431
40/40 [==============================] - 8s 210ms/sample - loss: 309496.7203 - model_loss: 7.8259 - model_1_loss: 2325.2710
[309496.7203125, 7.825928, 2325.271]
Training iter: 146
Gan loss: [1160754.8, 0.04701528, 11607.548]; Disc loss: 0.0141745675355196
Training iter: 147
Gan loss: [1134928.4, 0.04228715, 11349.283]; Disc loss: 0.01227340754121542
Training iter: 148
Gan loss: [1165200.6, 0.04048764, 11652.006]; Disc loss: 0.011746837757527828
Training iter: 149
Gan loss: [1174414.0, 0.034266587, 11744.14]; Disc loss: 0.01082308404147625
Training iter: 150
Gan loss: [1114976.2, 0.05025635, 11149.763]; Disc loss: 0.013916357420384884
40/40 [==============================] - 2s 43ms/sample - loss: 56.7436
40/40 [==============================] - 2s 43ms/sample - loss: 0.3469
40/40 [==============================] - 8s 210ms/sample - loss: 326772.4828 - model_loss: 7.3689 - model_1_loss: 2336.3301
[326772.4828125, 7.368861, 2336.33]
Training iter: 151
Gan loss: [1146680.6, 0.049566496, 11466.807]; Disc loss: 0.011916520074009895
Training iter: 152
Gan loss: [1136126.1, 0.041203793, 11361.262]; Disc loss: 0.011598815210163593
Training iter: 153
Gan loss: [1182779.1, 0.036556758, 11827.791]; Disc loss: 0.010532251559197903
Training iter: 154
Gan loss: [1143340.4, 0.040479705, 11433.404]; Disc loss: 0.01156768947839737
Training iter: 155
Gan loss: [1173513.2, 0.036533393, 11735.133]; Disc loss: 0.012140322476625443
40/40 [==============================] - 2s 43ms/sample - loss: 57.0080
40/40 [==============================] - 2s 43ms/sample - loss: 0.3042
40/40 [==============================] - 8s 210ms/sample - loss: 317835.6250 - model_loss: 7.4337 - model_1_loss: 2355.3647
[317835.625, 7.43373, 2355.3647]
Training iter: 156
Gan loss: [1195598.2, 0.03890349, 11955.982]; Disc loss: 0.011179516091942787
Training iter: 157
Gan loss: [1166358.2, 0.04117378, 11663.583]; Disc loss: 0.012627935968339443
Training iter: 158
Gan loss: [1182488.1, 0.034626286, 11824.882]; Disc loss: 0.009998848661780357
Training iter: 159
Gan loss: [1155925.8, 0.030425612, 11559.258]; Disc loss: 0.009055189788341522
Training iter: 160
Gan loss: [1173205.6, 0.030368023, 11732.057]; Disc loss: 0.008875762112438679
40/40 [==============================] - 2s 43ms/sample - loss: 56.3763
40/40 [==============================] - 2s 43ms/sample - loss: 0.3308
40/40 [==============================] - 8s 210ms/sample - loss: 323162.5562 - model_loss: 7.6571 - model_1_loss: 2377.6074
[323162.55625, 7.657073, 2377.6074]
Training iter: 161
Gan loss: [1169962.9, 0.033084303, 11699.629]; Disc loss: 0.009560410864651203
Training iter: 162
Gan loss: [1192036.0, 0.032044075, 11920.36]; Disc loss: 0.008842015638947487
Training iter: 163
Gan loss: [1170281.2, 0.046444222, 11702.8125]; Disc loss: 0.012678483501076698
Training iter: 164
Gan loss: [1136232.5, 0.04430159, 11362.325]; Disc loss: 0.011608184315264225
Training iter: 165
Gan loss: [1168764.2, 0.033446588, 11687.643]; Disc loss: 0.009671967476606369
40/40 [==============================] - 2s 43ms/sample - loss: 57.3613
40/40 [==============================] - 2s 43ms/sample - loss: 0.2606
40/40 [==============================] - 8s 211ms/sample - loss: 310827.1000 - model_loss: 6.8077 - model_1_loss: 2285.2051
[310827.1, 6.8077106, 2285.205]
Training iter: 166
Gan loss: [1164450.1, 0.03554631, 11644.501]; Disc loss: 0.01030644029378891
Training iter: 167
Gan loss: [1170915.0, 0.03209965, 11709.149]; Disc loss: 0.009207401424646378
Training iter: 168
Gan loss: [1222502.0, 0.030217737, 12225.02]; Disc loss: 0.008520419709384441
Training iter: 169
Gan loss: [1172224.6, 0.030864213, 11722.246]; Disc loss: 0.00913780927658081
Training iter: 170
Gan loss: [1225333.2, 0.025688663, 12253.333]; Disc loss: 0.007643293589353561
40/40 [==============================] - 2s 43ms/sample - loss: 57.1432
40/40 [==============================] - 2s 43ms/sample - loss: 0.2804
40/40 [==============================] - 8s 210ms/sample - loss: 325904.8469 - model_loss: 6.6015 - model_1_loss: 2411.7451
[325904.846875, 6.6015224, 2411.745]
Training iter: 171
Gan loss: [1224777.4, 0.027599849, 12247.773]; Disc loss: 0.007957471534609795
Training iter: 172
Gan loss: [1189902.0, 0.031960193, 11899.0205]; Disc loss: 0.009947437793016434
Training iter: 173
Gan loss: [1154906.4, 0.03367803, 11549.063]; Disc loss: 0.01056547462940216
Training iter: 174
Gan loss: [1196805.6, 0.032094773, 11968.057]; Disc loss: 0.009108176454901695
Training iter: 175
Gan loss: [1172690.6, 0.033149954, 11726.906]; Disc loss: 0.009301776066422462
40/40 [==============================] - 2s 43ms/sample - loss: 56.4560
40/40 [==============================] - 2s 43ms/sample - loss: 0.2834
40/40 [==============================] - 8s 210ms/sample - loss: 325599.5453 - model_loss: 7.2177 - model_1_loss: 2440.6936
[325599.5453125, 7.217687, 2440.6936]
Training iter: 176
Gan loss: [1150724.8, 0.032332897, 11507.248]; Disc loss: 0.010250741615891457
Training iter: 177
Gan loss: [1152354.6, 0.030664688, 11523.546]; Disc loss: 0.008916374295949936
Training iter: 178
Gan loss: [1217305.2, 0.028070707, 12173.053]; Disc loss: 0.008323583751916885
Training iter: 179
Gan loss: [1164130.6, 0.031427857, 11641.307]; Disc loss: 0.008818118833005428
Training iter: 180
Gan loss: [1166208.0, 0.036034986, 11662.08]; Disc loss: 0.009510201402008533
40/40 [==============================] - 2s 43ms/sample - loss: 56.6097
40/40 [==============================] - 2s 43ms/sample - loss: 0.2501
40/40 [==============================] - 8s 210ms/sample - loss: 312276.7328 - model_loss: 6.5155 - model_1_loss: 2292.5527
[312276.7328125, 6.5155053, 2292.5527]
Training iter: 181
Gan loss: [1120518.0, 0.03491091, 11205.18]; Disc loss: 0.008748931810259819
Training iter: 182
Gan loss: [1180571.4, 0.032908045, 11805.714]; Disc loss: 0.009020635858178139
Training iter: 183
Gan loss: [1193095.8, 0.02970197, 11930.958]; Disc loss: 0.008862907066941261
Training iter: 184
Gan loss: [1147717.2, 0.03557665, 11477.173]; Disc loss: 0.009978922083973885
Training iter: 185
Gan loss: [1185116.8, 0.025976334, 11851.168]; Disc loss: 0.0074571529403328896
40/40 [==============================] - 2s 43ms/sample - loss: 56.9187
40/40 [==============================] - 2s 43ms/sample - loss: 0.2988
40/40 [==============================] - 8s 210ms/sample - loss: 334022.8438 - model_loss: 6.9862 - model_1_loss: 2436.6233
[334022.84375, 6.986243, 2436.6233]
Training iter: 186
Gan loss: [1174276.1, 0.029363561, 11742.762]; Disc loss: 0.008434908464550972
Training iter: 187
Gan loss: [1153181.6, 0.032456644, 11531.816]; Disc loss: 0.009310789406299591
Training iter: 188
Gan loss: [1156180.2, 0.035275616, 11561.803]; Disc loss: 0.010808544233441353
Training iter: 189
Gan loss: [1154772.5, 0.025938835, 11547.725]; Disc loss: 0.007777978666126728
Training iter: 190
Gan loss: [1127915.4, 0.031112622, 11279.153]; Disc loss: 0.008594195358455181
40/40 [==============================] - 2s 43ms/sample - loss: 57.6818
40/40 [==============================] - 2s 43ms/sample - loss: 0.2722
40/40 [==============================] - 8s 210ms/sample - loss: 334886.9750 - model_loss: 7.1656 - model_1_loss: 2430.8999
[334886.975, 7.165616, 2430.9]
Training iter: 191
Gan loss: [1148576.4, 0.029803395, 11485.764]; Disc loss: 0.007999258115887642
Training iter: 192
Gan loss: [1172668.0, 0.023566544, 11726.68]; Disc loss: 0.0075641050934791565
Training iter: 193
Gan loss: [1123019.6, 0.031912148, 11230.196]; Disc loss: 0.009171631187200546
Training iter: 194
Gan loss: [1170354.0, 0.027690649, 11703.54]; Disc loss: 0.008314410224556923
Training iter: 195
Gan loss: [1165402.8, 0.030698102, 11654.027]; Disc loss: 0.00864216685295105
40/40 [==============================] - 2s 43ms/sample - loss: 56.7989
40/40 [==============================] - 2s 43ms/sample - loss: 0.2461
40/40 [==============================] - 8s 210ms/sample - loss: 322221.7328 - model_loss: 6.8562 - model_1_loss: 2399.1221
[322221.7328125, 6.8562403, 2399.122]
Training iter: 196
Gan loss: [1206731.2, 0.024376929, 12067.3125]; Disc loss: 0.007431225851178169
Training iter: 197
Gan loss: [1176699.5, 0.025427561, 11766.995]; Disc loss: 0.00768125569447875
Training iter: 198
Gan loss: [1128106.0, 0.03060368, 11281.06]; Disc loss: 0.009089094586670399
Training iter: 199
Gan loss: [1161288.6, 0.02401467, 11612.886]; Disc loss: 0.006670346949249506
